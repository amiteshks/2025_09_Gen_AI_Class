{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20fb6f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def ask_question_local_llm(prompt):\n",
    "    print(f\"User asked: {prompt}\")\n",
    "    # my_client.chat.completions.create\n",
    "\n",
    "    # Run a prompt against a local model (e.g., llama2)\n",
    "    response = ollama.chat(\n",
    "        model='llama3',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assitant - Respond in one line\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(response['message']['content'])\n",
    "\n",
    "    return response['message']['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8d8e45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(override=True, dotenv_path=\"../.env\")\n",
    "my_api_key = os.getenv(\"OPEN_AI_API_KEY\")\n",
    "\n",
    "my_client = OpenAI(api_key=my_api_key)\n",
    "my_client\n",
    "\n",
    "def ask_question_open_ai(prompt):\n",
    "\n",
    "    print(f\"User asked: {prompt}\")\n",
    "    # my_client.chat.completions.create\n",
    "\n",
    "    llm_response = my_client.chat.completions.create(\n",
    "        model=\"gpt-5-nano\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Answer as concisely as possible.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    print (llm_response)\n",
    "\n",
    "    return llm_response.choices[0].message.content  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7064ab55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------OPEN AI RESPONSE-------------------\n",
      "User asked: where is ocean?\n",
      "ChatCompletion(id='chatcmpl-CKVb0gzLuqlwDclt540Lvg0iyIyeF', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Oceans are on Earth, surrounding the continents. They cover about 71% of the planet’s surface.\\n\\nFive major oceans:\\n- Pacific: between Asia/Australia and the Americas\\n- Atlantic: between the Americas and Europe/Africa\\n- Indian: between Africa/Asia/Australia\\n- Southern: around Antarctica\\n- Arctic: around the North Pole\\n\\nIf you tell me your location, I can name the closest ocean to you.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1759004050, model='gpt-5-nano-2025-08-07', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=740, prompt_tokens=28, total_tokens=768, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=640, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "Time taken by OpenAI: 5.293970108032227 seconds\n",
      "\n",
      "OpenAI says: Oceans are on Earth, surrounding the continents. They cover about 71% of the planet’s surface.\n",
      "\n",
      "Five major oceans:\n",
      "- Pacific: between Asia/Australia and the Americas\n",
      "- Atlantic: between the Americas and Europe/Africa\n",
      "- Indian: between Africa/Asia/Australia\n",
      "- Southern: around Antarctica\n",
      "- Arctic: around the North Pole\n",
      "\n",
      "If you tell me your location, I can name the closest ocean to you.\n",
      "\n",
      "\n",
      "-------------------LOCAL LLM RESPONSE-------------------\n",
      "User asked: where is ocean?\n",
      "Oceans cover approximately 71% of the Earth's surface, surrounding all continents and separating them, with the five oceans being the Pacific Ocean, Atlantic Ocean, Indian Ocean, Arctic Ocean, and Southern Ocean.\n",
      "Time taken by Local LLM: 2.216209888458252 seconds\n",
      "\n",
      "Local LLM says: Oceans cover approximately 71% of the Earth's surface, surrounding all continents and separating them, with the five oceans being the Pacific Ocean, Atlantic Ocean, Indian Ocean, Arctic Ocean, and Southern Ocean.\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "while True:\n",
    "    # Ask user for a question\n",
    "    user_prompt = input(\"Ask something: \")\n",
    "\n",
    "    if (user_prompt.lower() != 'quit'):\n",
    "        # Get and print the response\n",
    "        print (\"-------------------OPEN AI RESPONSE-------------------\")\n",
    "        start = time.time()\n",
    "        response_openai = ask_question_open_ai(user_prompt)\n",
    "        end = time.time()   \n",
    "        print(f\"Time taken by OpenAI: {end - start} seconds\")\n",
    "        print(\"\\nOpenAI says:\", response_openai)\n",
    "\n",
    "        print (\"\\n\\n-------------------LOCAL LLM RESPONSE-------------------\")\n",
    "        start = time.time()\n",
    "        response_local = ask_question_local_llm(user_prompt)\n",
    "        end = time.time()   \n",
    "        print(f\"Time taken by Local LLM: {end - start} seconds\")\n",
    "        print(\"\\nLocal LLM says:\", response_local)        \n",
    "\n",
    "        # add delay of 3 seconds\n",
    "        time.sleep(3)\n",
    "    else:\n",
    "        print(\"Exiting...\")\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370a3762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
